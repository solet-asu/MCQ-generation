{
    'p1': {
        'id': 'anthropology_1_2',
        'title': 'Passage',
        'text': """Biological anthropology focuses on the earliest processes in the biological and sociocultural development of human beings as well as the biological diversity of contemporary humans. In other words, biological anthropologists study the origins, evolution, and diversity of our species. Some biological anthropologists use genetic data to explore the global distribution of human traits such as blood type or the ability to digest dairy products. Some study fossils to learn how humans have evolved and migrated. Some study our closest animal relatives, the primates, in order to understand what biological and social traits humans share with primates and explore what makes humans unique in the animal world.\n\n
The Dutch primatologist Carel van Schaik spent six years observing orangutans in Sumatra, discovering that these reclusive animals are actually much more social than previously thought (2004). Moreover, van Schaik observed that orangutans use a wide variety of tools and pass down skills to their young. By studying these primates, van Schaik and other biological anthropologists gain insight into the origins of human intelligence, technology, and culture. These researchers also warn that habitat loss, illegal hunting, and the exotic pet trade threaten the survival of our fascinating primate cousins.\n\n
Biological anthropologists frequently combine research among primates with evidence from the human fossil record, genetics, neuroscience, and geography to answer questions about human evolution. Sometimes their insights are startling and unexpected. Anthropologist Lynne Isbell argues that snakes have played a key role in the evolution of human biology, particularly our keen sense of sight and our ability to communicate through language (Isabell, 2009). Isbell's "snake detection theory" posits that primates developed specialized visual perception as well as the ability to communicate what they were seeing in order to alert others to the threat of venomous snakes in their environment. She points to the near-universal fear of snakes shared by both humans and primates and has documented the prevalence of snake phobia in human myth and folklore. Isbell's research highlights how human-animal relations are central to humanity, shaping both biology and culture.\n\n
Not all biological anthropologists study primates. Many biological anthropologists study fossilized remains in order to chart the evolution of early hominins, the evolutionary ancestors of modern humans. In this field of study, anthropologists consider the emergence and migration of the various species in the hominin family tree as well as the conditions that promoted certain biological and cultural traits. Some biological anthropologists examine the genetic makeup of contemporary humans in order to learn how certain genes and traits are distributed in human populations across different environments. Others examine human genetics looking for clues about the relationships between early modern humans and other hominins, such as Neanderthals."""
    },
    'p2': {
        'id': 'anthropology_1_3',
        'title': 'Passage',
        'text': """As you might guess, linguistic anthropology focuses on language. Linguistic anthropologists view language as a primary means by which humans create their diverse cultures. Language combines biological and social elements. Some linguistic anthropologists study the origins of language, asking how language emerged in our biological evolution and sociocultural development and what aspects of language might have given early hominins an evolutionary advantage. Other linguistic anthropologists are interested in how language shapes our thinking processes and our views of the world. In addition to its cognitive aspects, language is a powerful tool for getting things done. Linguistic anthropologists also study how people use language to form communities and identities, assert power, and resist authority.\n\n
Linguistic anthropologists frequently conduct the same kinds of long-term, immersive research that cultural anthropologists do. Christopher Ball spent a year living and traveling with the Wauja, an indigenous group in Brazil (2018). He describes the many routine and ritualized ways of speaking in this community and how each kind of talk generates specific types of social action. "Chief speech" is used by leaders, while "bringing the spirits" is used for healing the sick. Ceremonial language is used for giving people names and for conducting exchanges between different indigenous groups. Ball, like many linguistic anthropologists, also examined public speeches, such as the ones delivered by Wauja leaders to protest a dam on a nearby river. Ball also analyzed the forms of language used by state officials and development workers to marginalize and subordinate indigenous groups such as the Wauja.\n\n
Language is central to the way we conceptualize ourselves and our lives. Have you ever been asked to write an essay about yourself, perhaps as part of a school assignment or college application? If so, you might have used different phrases and concepts than if you'd been chatting with a new acquaintance. The purpose and intended audience of our language use shapes the way we represent ourselves and our actions.\n\n
Anthropologist Summerson Carr examined an addiction treatment program for homeless women in the midwestern United States, looking at the role of language in the therapeutic process (2011). After observing therapy sessions and self-help meetings, she describes how addiction counselors promote a certain kind of "healthy talk" that conveys deep cultural notions about personhood and responsibility. As patients master this "healthy talk," they learn to demonstrate progress by performing very scripted ways of speaking about themselves and their addiction."""
    },
    'p3': {
        'id': 'anthropology_2_3',
        'title': 'Passage',
        'text': """Ethnography is still commonly used by cultural anthropologists. Practitioners today consult multiple informants during their research in order to gather a variety of perspectives on a culture or society. No one person has a full or authoritative view of their own culture; multiple viewpoints are essential to a full description. Many early anthropological studies only invited male perspectives, introducing a male bias into the resulting ethnographies. Now, anthropologists deliberately seek varied perspectives, consulting people of different genders and ages and who occupy different roles.\n\n
Anthropologists can introduce significant bias into an ethnography. Having an ethnocentric or etic perspective means someone is judging a culture according to the standards of their own culture and belief system. To observe a culture from the perspective of the people being researched is to have an emic perspective. In addition, an anthropologist's interpretation of the information gathered can significantly alter their research findings. Earlier anthropologists were primarily male and White, so their findings were based on interpretations made through these lenses. Feminist anthropology attempts to address this male bias. In the 1920s, female anthropologists such as Zora Neale Hurston and Ruth Benedict began publishing in the field, but not until the 1928 publication of Margaret Mead's Coming of Age in Samoa did a female anthropologist gain prominence.\n\n
Women's contributions and perspectives became much more pronounced in the later parts of the 20th century. Feminist anthropologists seek not only to claim a role for themselves in the field equal to that offered to men but also to expand the focal points of anthropological inquiry to include areas of life such as family, marriage, and child-rearing, as well as the economic and social roles played by women. The dominance of male anthropologists had biased analysis of human societies toward male-dominated roles and activities. It was also assumed that women in early societies had subservient roles to men, when in fact most early societies have now been found to be very egalitarian, with equal status accorded to women and men. Feminist anthropology has both expanded research to include women's roles and aimed to understand the gender roles in other societies on their own terms, rather than according to the gender roles of the researcher's own society.\n\n
Other perspectives emerged in anthropology in the 1970s as more members of minority groups began entering the field. One category of minority voices that has been a significant asset to anthropology is that of people with Indigenous ancestors. Practitioners with this type of background are part of a subfield called Indigenous anthropology."""
    },
    'p4': {
        'id': 'anthropology_4_4',
        'title': 'Passage',
        'text': """The theory of natural selection has five main components:
All organisms are capable of producing offspring faster than the food supply increases.\n\n
All organisms show variation.\n\n
There is a fierce struggle for existence, and those with the most suitable variations are most likely to survive and reproduce.\n\n
Variations, or traits, are passed on to offspring (inherited).\n\n
Small changes in every generation lead to major changes over long periods of time.\n\n
A popular but often-misunderstood concept related to natural selection is the term survival of the fittest. Survival of the fittest does not necessarily mean that the biggest and fastest survive; instead, it refers to those who are most evolutionarily fit. This means that an organism has traits that are sufficient for survival and will be passed on to future generations. The term survival of the fittest was not even introduced by Darwin; rather, it was first used by English philosopher, anthropologist, and sociologist Herbert Spencer, who promoted the now discredited ideology of social Darwinism. Social Darwinism applied the concept of Darwin's biological evolution to human societies, proposing that human culture was progressing toward the "perfect human." Spencer's writings became integrally related to the 19th-century rise of scientific racism and European colonialism.\n\n
Moth with speckled wings resting on the trunk of a tree with bark showing a similar pattern and coloration.\n\n
Examples of Darwin's theory of natural selection can be found throughout the natural world. Perhaps one of the best known is the color change observed in peppered moths in England during the 19th century. Before the Industrial Revolution, peppered moths in England were a light grey color, well camouflaged on tree branches and less likely to be eaten by birds. Occasionally, through the process of mutation, black moths would appear in the population, but these were usually quickly eaten because they were more visible against light-colored bark. When soot from coal factories began to cover the bark of the trees, the black moths became better camouflaged and the white moths were now more visible. Consequently, the black moths were the ones to survive to reproduce, while the white ones were eaten. In a few decades, all the peppered moths in the cities were black. The process was termed industrial melanism. As coal usage decreased and the bark of the trees once again became lighter in color, white moths again dominated the urban areas.\n\n
Examples of natural selection in modern times are numerous. Pesticide resistance in insects is a classic example. Pesticide resistance refers to the decreasing susceptibility of a pest population to a pesticide that previously was effective at controlling it. Pest species evolve pesticide resistance via natural selection, with the most resistant individuals surviving to pass on their ability to resist the pesticide to their offspring. Another good example is the rise of "superbugs," bacteria that have become increasingly resistant to antibiotics."""
    },
    'p5': {
        'id': 'anthropology_9_1',
        'title': 'Passage',
        'text': """Critical race theory (CRT), developed by legal scholars in the 1980s, asserts that much of the inequity experienced by oppressed people in the United States can be understood through the critical lens of race. CRT states that racism is endemic, or regularly found in the laws, policies, and institutions of the United States. Thus, people who are socialized in American institutions often do not see the ways in which racism plays out in their daily lives. Notions of color blindness and meritocracy uphold the idea that racism either does not exist or is actually related to class, socioeconomics, or other factors. Color blindness is the idea that people "don't see color," meaning that they are unaware of the ways in which someone may experience the world because of the color of their skin. A meritocracy is a system in which people succeed entirely through their own hard work; thus, someone who believes in the notion of meritocracy overlooks any structural or racial inequities that may keep individuals from accessing the resources necessary for success (Delgado and Stefancic 2013). In the United States, these two concepts are often used together to blame poor (especially poor Black) individuals and families for their own misfortunes instead of looking to structural causes of poverty and income inequality. The term welfare queen is often used by politicians and the media to refer to a specific (Black or minority) demographic, even though statistically, White women are the most common recipients of government benefits. One way to challenge everyday endemic racism is to utilize counter-storytelling. These stories counteract the socialized assumptions that keep people of color marginalized. For instance, counter-stories are important in challenging the power of stereotypes such as the "welfare queen."\n\n
Critical race theory has become a hotly debated topic among politicians in the United States. CRT is often misunderstood by critics, who see it as a one-sided examination of (particularly American) history and society because CRT examines society through the lens of power and oppression. It often focuses on which groups benefit from cultural changes, including such things as civil rights legislation, essential to a democracy's guarantee of equal opportunity and protection under the law. In anthropology, CRT is an important tool for examining both modern institutions and the experiences of individuals in the United States, especially in regard to social inequalities. As just one example, CRT can shed light on the decisions made by those in power when redrawing the boundaries of voting districts. These decisions are often made with the goal of cementing a majority for a particular political party while diluting the voting power of citizens who don't typically belong that party, a practice known as gerrymandering. It is important for social scientists to consider the potential role of race and racism in making these decisions. If race and/or racism were found to be a factor, then these political decisions would be considered an example of systemic oppression."""
    },
    'p6': {
        'id': 'history_1_2',
        'title': 'Passage',
        'text': """During the Middle Ages, most Europeans lived in small villages that consisted of a manorial house or castle for the lord, a church, and simple homes for the peasants or serfs, who made up about 60 percent of western Europe's population. The lords owned the land; knights gave military service to a lord and carried out his justice; serfs worked the land in return for the protection offered by the lord's castle or the walls of his city, into which they fled in times of danger from invaders. Thus, although they were technically free, serfs were effectively bound to the land they worked, which supported them and their families as well as the lord and all who depended on him. The Catholic Church, the only church in Europe at the time, also owned vast tracts of land and became very wealthy by collecting not only tithes (taxes consisting of 10 percent of annual earnings) but also rents on its lands.\n\n
Women often died in childbirth, and perhaps one-third of children died before the age of five. Without sanitation or medicine, many people perished from diseases we consider inconsequential today; few lived to be older than forty-five. Entire families, usually including grandparents, lived in one- or two-room hovels that were cold, dark, and dirty. A fire was kept lit and was always a danger to the thatched roofs, while its constant smoke affected the inhabitants' health and eyesight.\n\n
In an agrarian society, the seasons dictate the rhythm of life. Idleness meant hunger. When the land began to thaw in early spring, peasants started tilling the soil with primitive wooden plows and crude rakes and hoes. Then they planted crops of wheat, rye, barley, and oats, reaping small yields that barely sustained the population. Bad weather, crop disease, or insect infestation could cause an entire village to starve or force the survivors to move to another location.\n\n
Early summer saw the first harvesting of hay, which was stored until needed to feed the animals in winter. Men and boys sheared the sheep, now heavy with wool from the cold weather, while women and children washed the wool and spun it into yarn. The coming of fall meant crops needed to be harvested and prepared for winter. Livestock was butchered and the meat smoked or salted to preserve it. Winter brought the people indoors to weave yarn into fabric, sew clothing, thresh grain, and keep the fires going."""
    },
    'p7': {
        'id': 'history_3_1',
        'title': 'Passage',
        'text': """Farther west, the Spanish in Mexico, intent on expanding their empire, looked north to the land of the Pueblo Natives. Under orders from King Philip II, Juan de Oñate explored the American southwest for Spain in the late 1590s. The Spanish hoped that what we know as New Mexico would yield gold and silver, but the land produced little of value to them. In 1610, Spanish settlers established themselves at Santa Fe—originally named La Villa Real de la Santa Fe de San Francisco de Asís, or "Royal City of the Holy Faith of St. Francis of Assisi"—where many Pueblo villages were located. Santa Fe became the capital of the Kingdom of New Mexico, an outpost of the larger Spanish Viceroyalty of New Spain, which had its headquarters in Mexico City.\n\n
As they had in other Spanish colonies, Franciscan missionaries labored to bring about a spiritual conquest by converting the Pueblo to Catholicism. At first, the Pueblo adopted the parts of Catholicism that dovetailed with their own long-standing view of the world. However, Spanish priests insisted that natives discard their old ways entirely and angered the Pueblo by focusing on the young, drawing them away from their parents. This deep insult, combined with an extended period of drought and increased attacks by local Apache and Navajo in the 1670s—troubles that the Pueblo came to believe were linked to the Spanish presence—moved the Pueblo to push the Spanish and their religion from the area. Pueblo leader Popé demanded a return to native ways so the hardships his people faced would end. To him and to thousands of others, it seemed obvious that "when Jesus came, the Corn Mothers went away." The expulsion of the Spanish would bring a return to prosperity and a pure, native way of life.\n\n
In 1680, the Pueblo launched a coordinated rebellion against the Spanish. The Pueblo Revolt killed over four hundred Spaniards and drove the rest of the settlers, perhaps as many as two thousand, south toward Mexico. However, as droughts and attacks by rival tribes continued, the Spanish sensed an opportunity to regain their foothold. In 1692, they returned and reasserted their control of the area. Some of the Spanish explained the Pueblo success in 1680 as the work of the Devil. Satan, they believed, had stirred up the Pueblo to take arms against God's chosen people—the Spanish—but the Spanish, and their God, had prevailed in the end."""
    },
    'p8': {
        'id': 'history_3_2',
        'title': 'Passage',
        'text': """After Jacques Cartier's voyages of discovery in the 1530s, France showed little interest in creating permanent colonies in North America until the early 1600s, when Samuel de Champlain established Quebec as a French fur-trading outpost. Although the fur trade was lucrative, the French saw Canada as an inhospitable frozen wasteland, and by 1640, fewer than four hundred settlers had made their home there. The sparse French presence meant that colonists depended on the local native Algonquian people; without them, the French would have perished. French fishermen, explorers, and fur traders made extensive contact with the Algonquian. The Algonquian, in turn, tolerated the French because the colonists supplied them with firearms for their ongoing war with the Iroquois. Thus, the French found themselves escalating native wars and supporting the Algonquian against the Iroquois, who received weapons from their Dutch trading partners. These seventeenth-century conflicts centered on the lucrative trade in beaver pelts, earning them the name of the Beaver Wars. In these wars, fighting between rival native peoples spread throughout the Great Lakes region.\n\n
A handful of French Jesuit priests also made their way to Canada, intent on converting the native inhabitants to Catholicism. The Jesuits were members of the Society of Jesus, an elite religious order founded in the 1540s to spread Catholicism and combat the spread of Protestantism. The first Jesuits arrived in Quebec in the 1620s, and for the next century, their numbers did not exceed forty priests. Like the Spanish Franciscan missionaries, the Jesuits in the colony called New France labored to convert the native peoples to Catholicism. They wrote detailed annual reports about their progress in bringing the faith to the Algonquian and, beginning in the 1660s, to the Iroquois. These documents are known as the Jesuit Relations, and they provide a rich source for understanding both the Jesuit view of the Native Americans and the Native response to the colonizers.\n\n
One Native convert to Catholicism, a Mohawk woman named Kateri Tekakwitha, so impressed the priests with her piety that a Jesuit named Claude Chauchetière attempted to make her a saint in the Church. However, the effort to canonize Tekakwitha faltered when leaders of the Church balked at elevating a "savage" to such a high status; she was eventually canonized in 2012. French colonizers pressured the native inhabitants of New France to convert, but they virtually never saw Native peoples as their equals."""
    },
    'p9': {
        'id': 'history_3_3',
        'title': 'Passage',
        'text': """Promoters of English colonization in North America, many of whom never ventured across the Atlantic, wrote about the bounty the English would find there. The English migrants who actually made the journey, however, had different goals. In Chesapeake Bay, English migrants established Virginia and Maryland with a decidedly commercial orientation. Though the early Virginians at Jamestown hoped to find gold, they and the settlers in Maryland quickly discovered that growing tobacco was the only sure means of making money. Thousands of unmarried, unemployed, and impatient young Englishmen, along with a few Englishwomen, pinned their hopes for a better life on the tobacco fields of these two colonies.\n\n
A very different group of English men and women flocked to the cold climate and rocky soil of New England, spurred by religious motives. Many of the Puritans crossing the Atlantic were people who brought families and children. While the English in Virginia and Maryland worked on expanding their profitable tobacco fields, the English in New England built towns focused on the church, where each congregation decided what was best for itself. Many historians believe the fault lines separating what later became the North and South in the United States originated in the profound differences between the Chesapeake and New England colonies.\n\n
The source of those differences lay in England's domestic problems. Increasingly in the early 1600s, the English state church—the Church of England, established in the 1530s—demanded conformity, or compliance with its practices, but Puritans pushed for greater reforms. By the 1620s, the Church of England began to see leading Puritan ministers and their followers as outlaws, a national security threat because of their opposition to its power. As the noose of conformity tightened around them, many Puritans decided to remove to New England.\n\n
The troubles in England escalated in the 1640s when civil war broke out, pitting Royalist supporters of King Charles I and the Church of England against Parliamentarians, the Puritan reformers and their supporters in Parliament. In 1649, the Parliamentarians gained the upper hand and, in an unprecedented move, executed Charles I. In the 1650s, therefore, England became a republic, a state without a king. English colonists in America closely followed these events. Indeed, many Puritans left New England and returned home to take part in the struggle against the king and the national church. The turmoil in England made the administration and imperial oversight of the Chesapeake and New England colonies difficult, and the two regions developed divergent cultures."""
    },
    'p10': {
        'id': 'history_3_4',
        'title': 'Passage',
        'text': """Everywhere in the American colonies, a crushing demand for labor existed to grow New World cash crops, especially sugar and tobacco. This need led Europeans to rely increasingly on Africans, and after 1600, the movement of Africans across the Atlantic accelerated. The English crown chartered the Royal African Company in 1672, giving the company a monopoly over the transport of enslaved African people to the English colonies. Over the next four decades, the company transported around 350,000 Africans from their homelands. By 1700, the tiny English sugar island of Barbados had a population of fifty thousand enslaved people, and the English had encoded the institution of chattel slavery into colonial law.\n\n
This new system of African slavery came slowly to the English colonists, who did not have slavery at home and preferred to use servant labor. Nevertheless, by the end of the seventeenth century, the English everywhere in America—and particularly in the Chesapeake Bay colonies—had come to rely on enslaved Africans. While Africans had long practiced slavery among their own people, it had not been based on race. Africans enslaved other Africans as war captives, for crimes, and to settle debts; they generally used enslaved people for domestic and small-scale agricultural work, not for growing cash crops on large plantations. Additionally, African slavery was often a temporary condition rather than a lifelong sentence, and, unlike New World slavery, it was typically not heritable.\n\n
The growing slave trade with Europeans had a profound impact on the people of West Africa, giving prominence to local chieftains and merchants who traded enslaved people for European textiles, alcohol, guns, tobacco, and food. Africans also charged Europeans for the right to trade in enslaved people and imposed taxes on enslaved people purchases. Different African groups and kingdoms even staged large-scale raids on each other to meet the demand for enslaved people.\n\n
Once sold to traders, all captured people sent to America endured the hellish Middle Passage, the transatlantic crossing, which took one to two months. By 1625, more than 325,800 Africans had been shipped to the New World, though many thousands perished during the voyage. An astonishing number, some four million, were transported to the Caribbean between 1501 and 1830. When they reached their destination in America, Africans found themselves trapped in shockingly brutal slave societies. In the Chesapeake colonies, they faced a lifetime of harvesting and processing tobacco.\n\n
Everywhere, Africans resisted slavery, and running away was common. In Jamaica and elsewhere, escaped enslaved people created maroon communities, groups that resisted recapture and eked out a living from the land, rebuilding their communities as best they could. When possible, they adhered to traditional ways, following spiritual leaders such as Vodun priests."""
    },
    'p11': {
        'id': 'lifespan_development_1_2',
        'title': 'Passage',
        'text': """In addition to studying what changes are expected and how they occur, developmental psychologists ask when we should expect certain skills to develop, and whether there are windows of opportunity for these that affect developmental outcomes. Is it possible to speed up development if we introduce an experience at just the right time? Is it possible to hinder or even prevent the development of a particular ability or characteristic altogether, such as speech? What are the impacts of highly enriching environments? What are the impacts of being deprived of certain experiences, such as human contact?\n\n
Scientists have learned that across nearly all psychological characteristics, humans are highly adaptable. They observe normative developmental outcomes, meaning those that are typical or expected, across a wide range of environmental conditions. Certainly, there are optimal environments for these developmental outcomes, but good outcomes occur even in suboptimal circumstances. This is central to resilience, an individual's capacity for and "process of adapting well in the face of adversity, trauma, tragedy, threats or even significant sources of stress" (American Psychological Association [APA], 2014). It takes extreme deprivation to severely restrict a developing human's potential, as well as such deprivation occurring at specific developmental times. In other words, resilience is common and lifespan development principles can be applied to increase the likelihood of resilience.\n\n
A critical period is the developmental age range in which certain experiences are required for a psychological or physical ability to develop (Colombo et al., 2019). For example, it appears that exposure to human speech is necessary in the early years of life for typical language development. Consider the 1970s case of Genie, a child who was severely neglected and isolated to the point that she was rarely spoken to. Upon her rescue at age thirteen years, Genie faced the monumental task of learning a language (a primary task of infants and toddlers) with an adolescent (post-pubescent) brain (Jones, 1995). Genie became the subject of intense study and remediation efforts by doctors, speech pathologists, and psychologists (Fromkin et al., 1974). Despite her extreme early deprivation, she made many improvements in language comprehension and speech production. However, her development of language differed markedly from what is normative. For example, language production and comprehension happen in the left hemisphere of the brain for the vast majority of humans, but Genie showed processing of language in her right cerebral hemisphere."""
    },
    'p12': {
        'id': 'lifespan_development_1_3',
        'title': 'Passage',
        'text': """Vygotsky (1978, 1998) proposed a sociocultural theory of cognitive development, emphasizing that thinking abilities are embedded within an individual's social and cultural context. Whereas Piaget's theory focused on a person's step-like journey of coming to understand the world, Vygotsky saw cognitive development as supported and propelled by social tools available to the individual learner. These social tools include language, direct support from others, and technological aids. Vygotsky, then, was among the first to recognize that language guides cognition and gives shape to ideas that can be readily communicated with others through words. One such example is private speech, whereby the learner may use words to audibly (or not) keep themselves on track during a difficult problem-solving session. If you've ever rehearsed a list of grocery items out loud while you searched for a place to record them, you've used language in such a way. Acronyms for remembering complex math concepts, such as PEMDAS (parentheses, exponents, multiplication, division, addition, and subtraction) for the order of arithmetic operations, are another example of language use supporting cognition.\n\n
The application of various forms of technology, another social tool, can allow an individual to perform complex tasks more easily than by relying on brain power alone. From this perspective, using a calculator to do basic calculations frees up the mind to think about the more important and complex parts of a word problem, for example. Word processing programs and apps that autocorrect spelling and grammar support thinking by allowing the writer to focus on the ideas of their message, instead of on the mechanics of writing.\n\n
Vygotsky is best known for championing social supports in propelling cognitive development and educational achievement. His notion of the zone of proximal development (ZPD) states that all of us are capable of thinking and achieving at a higher level than we may realize: there are concepts and ideas just beyond our current abilities that we are ready to master if only we have a little help, often from others. Educators and parents have used the idea of scaffolding to help learners achieve beyond their current level, gradually withdrawing support as the student becomes more competent. Learning how to ride a bicycle is a great example of scaffolding. Support for learning this difficult task can come through training wheels, or from a caregiver holding the bicycle seat while running alongside the child. As the child gains a sense of balance and masters the mechanics of pedaling and steering, the training wheels become less necessary and are eventually removed, and the caregiver lets go of the seat. The child has reached a new level of development with guided and temporary support."""
    },
    'p13': {
        'id': 'lifespan_development_1_4',
        'title': 'Passage',
        'text': """Research findings in psychology are often broken down by social or cultural sub-groups of particular interest or identification. These include biological sex, gender, race and ethnicity, religious beliefs, socioeconomic status, and cultural influences, among others. When developmental psychologists use these terms, they do so with the specific meanings they carry in psychology. These contexts are all important to the overall process of human development and our understanding of it.\n\n
Sex, gender, and sexual orientation are key components of human development and are distinctive terms (National Academies of Sciences, Engineering, & Medicine, 2022). An individual's sex is assigned at birth based on their biological anatomy and physiology (such as chromosomes). People may be assigned female, male, or intersex. An individual's sex should not be confused with their gender, which describes society's ideas about the roles, attitudes, and behaviors associated with someone's sex assignment. For example, being born with a penis results in being assigned the sex male; exhibiting behaviors such as participating in rough sports or suppressing emotions results in being associated with the gender male in cultures where those behaviors are associated with masculinity. Some people, researchers, and advocates aim to separate descriptors of sex (female and male) from those of gender (girl, woman, boy, man, nonbinary, and so on). While it is best to be as precise as possible, this practice is not universal and may be complicated when both sex and gender are involved in a topic or outcome. As a result, many studies or documents use sex and gender terms interchangeably.\n\n
The way a culture decides whether a characteristic or behavior is associated with a gender can also change over time. For example, in the United States the color blue is often associated with baby boys; however, if you looked to popular trends before the 1940s, pink was associated with boys and blue was associated with girls (Maglaty, 2011). Someone's psychological sense of their gender is their gender identity and reflects ideas about femininity, masculinity, non-binary characteristics, and other dimensions of gender. How someone labels their gender identity is also related to whether their gender matches society's expectations based on sex assignment. Conforming is denoted by the prefix cis- (such as a cis gender man) and non-conforming by the prefix trans- (such as a transgender individual). A person's sexual orientation includes their sexual identity, sexual behavior, and sexual attraction, or to whom someone is sexually attracted. Note that sexual attraction can differ from emotional attraction."""
    },
    'p14': {
        'id': 'lifespan_development_1_5',
        'title': 'Passage',
        'text': """A longitudinal design studies a group of participants over a period of time, re-assessing them at various points. If we are interested in the development of friendships during adolescence, we might recruit a group of fifty sixth-grade students. We would give them a personality inventory, collect background information about each, and ask them to complete surveys about their friendships. Then, we would find these same fifty participants at six-month or one-year intervals, re-assessing the same information. At the end of five or six years, we'd have a rich data set and a really good idea about how the number, type, and quality of friendships change across adolescence.\n\n
Often longitudinal studies are employed when researching various diseases in an effort to understand particular risk factors. Such studies often involve tens of thousands of individuals who are followed for several decades. Given the enormous number of people involved in these studies, researchers can feel confident that their findings can be generalized to the larger population. For instance, earlier longitudinal studies sponsored by the American Cancer Society provided some of the first scientific demonstrations of the now well-established links between increased rates of smoking and cancer (American Cancer Society, n.d.).\n\n
As with any research strategy, longitudinal research is not without limitations. For one, these studies require an incredible time investment by the researcher and research participants. Given that some longitudinal studies take years, if not decades, to complete, the results will not be known for a considerable period of time. Research participants must also be willing to continue their participation for an extended period of time, and this can be problematic. This is known as attrition, the gradual loss or dropping out of participants from the original pool. Another issue is test familiarity, known as practice effects. Since participants are given the same battery of measures including surveys multiple times, they might get used to the questions, which could alter the way they think about and respond to them.\n\n
Finally, and this is the most serious challenge in longitudinal research, the longer the study duration, the higher the risk of encountering cohort effects. This means that the research results, which in our hypothetical study would take five or six years to obtain, might end up being limited in their applicability beyond a certain cohort. Nevertheless, a longitudinal design comes closest to observing change within individuals over time, making this a highly valid and valuable approach."""
    },
    'p15': {
        'id': 'lifespan_development_9_3',
        'title': 'Passage',
        'text': """Adolescent thought is characterized by several other tendencies that stem from teens' new ability to think about what is possible. First is the ability to think in complex ways about abstract ideas. Adolescents become aware of the world of ideas that don't necessarily exist in physical form, and concepts, like justice, equality, equity, and truth take on new and profound importance. A child in the concrete operations stage might be able to talk about respect in simple terms, such as the give and take of mutual benefits (i.e., respect is when you are kind and share your things. An adolescent's description would be much more nuanced and might include a discussion of equality and fairness (another abstract yet real concept).\n\n
Adolescents are also able to think about multiple dimensions of a problem or situation and the way various factors combine to influence an observed outcome. For example, when faced with a dress code violation at school, a high school student might be able to see how the policy creates a standard against which all students are held, while also arguing against the lost class time that being sent home to change entails. Seeing the irony of such a situation is a hallmark of adolescent thinking and may lead to frustration and de-idealization of the adults who control their world. An appreciation of sarcasm, which relies on the ability to think in multiple dimensions and from multiple perspectives, also emerges in adolescence (Glenwright et al., 2017). Not only can adolescents begin to understand when sarcasm is being used, but they can begin to understand its functional use in public discourse. Questioning rules, especially rules that seem arbitrary, is another hallmark of the adolescent experience.\n\n
Because they can now think about possibilities, in both abstract ways and in multiple dimensions, adolescents also develop relativistic thinking, which is the belief that most truths and statements of fact are relative to the position of the observer (Chandler et al., 1990). Prior to this stage, children tend to think in absolutes (e.g., right versus wrong; good versus bad). Adolescents who have developed more relativistic thinking can simultaneously evaluate the possibility that both positions can exist, depending on whose perspective you are taking. For example, if two friends are discussing whose answer on a test was correct, a teenager would be able to see how both friends could be right given the context of their examples in the answer. They could then use this information to discuss with their instructor how to gain a better understanding of the material. When all things are possible and all perspectives can be considered, everyone can seem correct . . . and everyone can seem wrong. It's a matter of perspective."""
    },
    'p16': {
        'id': 'sociology_1_1',
        'title': 'Passage',
        'text': """All sociologists are interested in the experiences of individuals and how those experiences are shaped by interactions with social groups and society. To a sociologist, the personal decisions an individual makes do not exist in a vacuum. Cultural patterns, social forces and influences put pressure on people to select one choice over another. Sociologists try to identify these general patterns by examining the behavior of large groups of people living in the same society and experiencing the same societal pressures.\n\n
Consider the changes in U.S. families. The "typical" family in past decades consisted of married parents living in a home with their unmarried children. Today, the percent of unmarried couples, same-sex couples, single-parent and single-adult households is increasing, as well as is the number of expanded households, in which extended family members such as grandparents, cousins, or adult children live together in the family home. While 15 million mothers still make up the majority of single parents, 3.5 million fathers are also raising their children alone (U.S. Census Bureau, 2020).\n\n
Some sociologists study social facts—the laws, morals, values, religious beliefs, customs, fashions, rituals, and cultural rules that govern social life—that may contribute to these changes in the family. Do people in the United States view marriage and family differently over the years? Do employment and economic conditions play a role in families? Other sociologists are studying the consequences of these new patterns, such as the ways children influence and are influenced by them and/or the changing needs for education, housing, and healthcare.\n\n
Sociologists identify and study patterns related to all kinds of contemporary social issues. The "Stop and Frisk" policy, the emergence of new political factions, how Twitter influences everyday communication—these are all examples of topics that sociologists might explore.\n\n
A key component of the sociological perspective is the idea that the individual and society are inseparable. It is impossible to study one without the other. German sociologist Norbert Elias called the process of simultaneously analyzing the behavior of individuals and the society that shapes that behavior figuration.\n\n
Consider religion. While people experience religion in a distinctly individual manner, religion exists in a larger social context as a social institution. For instance, an individual's religious practice may be influenced by what government dictates, holidays, teachers, places of worship, rituals, and so on. In simpler terms, figuration means that as one analyzes the social institutions in a society, the individuals using that institution in any fashion need to be 'figured' in to the analysis."""
    },
    'p17': {
        'id': 'sociology_11_2',
        'title': 'Passage',
        'text': """
Functionalism\n\n
Functionalism emphasizes that all the elements of society have functions that promote solidarity and maintain order and stability in society. Hence, we can observe people from various racial and ethnic backgrounds interacting harmoniously in a state of social balance. Problems arise when one or more racial or ethnic groups experience inequalities and discriminations. This creates tension and conflict resulting in temporary dysfunction of the social system. To restore the society's pre-disturbed state or to seek a new equilibrium, the police department and various parts of the system require changes and compensatory adjustments.\n\n
Another way to apply the functionalist perspective to race and ethnicity is to discuss the way racism can contribute positively to the functioning of society by strengthening bonds between in-group members through the ostracism of out-group members. Consider how a community might increase solidarity by refusing to allow outsiders access. On the other hand, Rose (1951) suggested that dysfunctions associated with racism include the failure to take advantage of talent in the subjugated group, and that society must divert from other purposes the time and effort needed to maintain artificially constructed racial boundaries.\n\n
In the view of functionalism, racial and ethnic inequalities must have served an important function in order to exist as long as they have. Nash (1964) focused his argument on the way racism is functional for the dominant group, for example, suggesting that racism morally justifies a racially unequal society.\n\n
Interactionism\n\n
For symbolic interactionists, race and ethnicity provide strong symbols as sources of identity. In fact, some interactionists propose that the symbols of race, not race itself, are what lead to racism. Famed Interactionist Herbert Blumer (1958) suggested that racial prejudice is formed through interactions between members of the dominant group: Without these interactions, individuals in the dominant group would not hold racist views. These interactions contribute to an abstract picture of the subordinate group that allows the dominant group to support its view of the subordinate group, and thus maintains the status quo. An example of this might be an individual whose beliefs about a particular group are based on images conveyed in popular media, and those are unquestionably believed because the individual has never personally met a member of that group.\n\n
Another way to apply the interactionist perspective is to look at how people define their races and the race of others. Some people who claim a White identity have a greater amount of skin pigmentation than some people who claim a Black identity; how did they come to define themselves as Black or White?"""
    },
    'p18': {
        'id': 'sociology_3_1',
        'title': 'Passage',
        'text': """Although human societies have much in common, cultural differences are far more prevalent than cultural universals. For example, while all cultures have language, analysis of conversational etiquette reveals tremendous differences. In some Middle Eastern cultures, it is common to stand close to others in conversation. Americans keep more distance and maintain a large "personal space." Additionally, behaviors as simple as eating and drinking vary greatly from culture to culture. Some cultures use tools to put the food in the mouth while others use their fingers. If your professor comes into an early morning class holding a mug of liquid, what do you assume they are drinking? In the U.S., it's most likely filled with coffee, not Earl Grey tea, a favorite in England, or Yak Butter tea, a staple in Tibet.\n\n
Often, however, people express disgust at another culture's cuisine. They might think that it's gross to eat raw meat from a donkey or parts of a rodent, while they don't question their own habit of eating cows or pigs.\n\n
Such attitudes are examples of ethnocentrism, which means to evaluate and judge another culture based on one's own cultural norms. Ethnocentrism is believing your group is the correct measuring standard and if other cultures do not measure up to it, they are wrong. As sociologist William Graham Sumner (1906) described the term, it is a belief or attitude that one's own culture is better than all others. Almost everyone is a little bit ethnocentric.\n\n
A high level of appreciation for one's own culture can be healthy. A shared sense of community pride, for example, connects people in a society. But ethnocentrism can lead to disdain or dislike of other cultures and could cause misunderstanding, stereotyping, and conflict. Cultural imperialism is the deliberate imposition of one's own cultural values on another culture.\n\n
Colonial expansion by Portugal, Spain, Netherlands, and England grew quickly in the fifteenth century was accompanied by severe cultural imperialism. European colonizers often viewed the people in these new lands as uncultured savages who needed to adopt Catholic governance, Christianity, European dress, and other cultural practices.\n\n
A modern example of cultural imperialism may include the work of international aid agencies who introduce agricultural methods and plant species from developed countries into areas that are better served by indigenous varieties and agricultural approaches to the particular region. Another example would be the deforestation of the Amazon Basin as indigenous cultures lose land to timber corporations."""
    },
    'p19': {
        'id': 'sociology_4_1',
        'title': 'Passage',
        'text': """In the eighteenth century, Europe experienced a dramatic rise in technological invention, ushering in an era known as the Industrial Revolution. What made this period remarkable was the number of new inventions that influenced people's daily lives. Within a generation, tasks that had until this point required months of labor became achievable in a matter of days. Before the Industrial Revolution, work was largely person- or animal-based, and relied on human workers or horses to power mills and drive pumps.\n\n
Steam power began appearing everywhere. Instead of paying artisans to painstakingly spin wool and weave it into cloth, people turned to textile mills that produced fabric quickly at a better price and often with better quality. Rather than planting and harvesting fields by hand, farmers were able to purchase mechanical seeders and threshing machines that caused agricultural productivity to soar. Products such as paper and glass became available to the average person, and the quality and accessibility of education and health care soared. Gas lights allowed increased visibility in the dark, and towns and cities developed a nightlife.\n\n
One of the results of increased productivity and technology was the rise of urban centers. Workers flocked to factories for jobs, and the populations of cities became increasingly diverse. The new generation became less preoccupied with maintaining family land and traditions and more focused on acquiring wealth and achieving upward mobility for themselves and their families. People wanted their children and their children's children to continue to rise to the top, and as capitalism increased, so did social mobility.\n\n
It was during the eighteenth and nineteenth centuries of the Industrial Revolution that sociology was born. Life was changing quickly and the long-established traditions of the agricultural eras did not apply to life in the larger cities. Masses of people were moving to new environments and often found themselves faced with horrendous conditions of filth, overcrowding, and poverty. Social scientists emerged to study the relationship between the individual members of society and society as a whole.\n\n
It was during this time that power moved from the hands of the aristocracy and "old money" to business-savvy newcomers who amassed fortunes in their lifetimes. Families such as the Rockefellers and the Vanderbilts became the new power players and used their influence in business to control aspects of government as well. Eventually, concerns over the exploitation of workers led to the formation of labor unions and laws that set mandatory conditions for employees. Although the introduction of new technology at the end of the nineteenth century ended the industrial age, much of our social structure and social ideas—like family, childhood, and time standardization—have a basis in industrial society."""
    },
    'p20': {
        'id': 'sociology_5_2',
        'title': 'Passage',
        'text': """Some experts assert that who we are is a result of nurture—the relationships and caring that surround us. Others argue that who we are is based entirely in genetics. According to this belief, our temperaments, interests, and talents are set before birth. From this perspective, then, who we are depends on nature.\n\n
One way researchers attempt to measure the impact of nature is by studying twins. Some studies have followed identical twins who were raised separately. The pairs shared the same genetics but in some cases were socialized in different ways. Instances of this type of situation are rare, but studying the degree to which identical twins raised apart are the same and different can give researchers insight into the way our temperaments, preferences, and abilities are shaped by our genetic makeup versus our social environment.\n\n
For example, in 1968, twin girls were put up for adoption, separated from each other, and raised in different households. The adoptive parents, and certainly the babies, did not realize the girls were one of five pairs of twins who were made subjects of a scientific study (Flam 2007).\n\n
In 2003, the two women, then age thirty-five, were reunited. Elyse Schein and Paula Bernstein sat together in awe, feeling like they were looking into a mirror. Not only did they look alike but they also behaved alike, using the same hand gestures and facial expressions (Spratling 2007). Studies like these point to the genetic roots of our temperament and behavior.\n\n
Though genetics and hormones play an important role in human behavior, sociology's larger concern is the effect society has on human behavior, the "nurture" side of the nature versus nurture debate. What race were the twins? From what social class were their parents? All these factors affected the lives of the twins as much as their genetic makeup and are critical to consider as we look at life through the sociological lens.\n\n
Sociologists all recognize the importance of socialization for healthy individual and societal development. Structural functionalists would say that socialization is essential to society, both because it trains members to operate successfully within it and because it perpetuates culture by transmitting it to new generations. A conflict theorist might argue that socialization reproduces inequality from generation to generation by conveying different expectations and norms to those with different social characteristics. For example, individuals are socialized differently by gender, social class, and race. As in Chris Langan's case, this creates different (unequal) opportunities. An interactionist studying socialization is concerned with face-to-face exchanges and symbolic communication. For example, dressing baby boys in blue and baby girls in pink is one small way we convey messages about differences in gender roles."""
    },
}
