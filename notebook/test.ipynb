{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prompt_fetch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o\"\n",
    "system_prompt = \"You are a helpful assistant\"\n",
    "user_prompt = \"What does ASU stand for?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent = Agent(model=model, system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': None,\n",
       " 'system_prompt': 'You are a helpful assistant',\n",
       " 'user_prompt': 'What does ASU stand for?',\n",
       " 'model': 'gpt-4o',\n",
       " 'completion': None,\n",
       " 'extraction': None,\n",
       " 'execution_time': 'None'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_agent.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '\"ASU\" can stand for several things depending on the context. Some common interpretations include:\\n\\n1. **Arizona State University** - A public research university located in Arizona, USA.\\n2. **Appalachian State University** - A public university in Boone, North Carolina, USA.\\n3. **Alabama State University** - A historically black university in Montgomery, Alabama, USA.\\n4. **Australian Signals Directorate** - While not commonly abbreviated as ASU, in military contexts, \"ASU\" could sometimes refer to units within signal corps, although typically \"ASD\" is used.\\n5. **Army Service Uniform** - Refers to the formal military uniform worn by personnel in the U.S. Army.\\n6. **Aggregation Switch Unit** - In telecommunications or networking contexts, this refers to network hardware.\\n\\nIf you have a specific context in mind, please let me know, and I can provide a more targeted definition.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_agent.completion_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system_prompt_inferential': '[ROLE]:\\nYou are an experienced college instructor. You are an expert in writing multiple-choice questions to assess students’ understanding of academic texts (e.g., chapters in textbooks, academic articles).\\n\\n[TASK]:\\nYou are asked to write an inferential multiple-choice question based on an academic text provided by the user. \\nFollow the guidelines in [GUIDELINES] to do exactly what you are instructed to do. \\n\\n[DEFINITION]\\n**What are inferential questions?**\\nInferential questions require students to go beyond the explicit information in a text and draw conclusions based on evidence, reasoning, and prior knowledge. Unlike literal questions, which ask for directly stated facts, inferential questions challenge students to interpret, analyze, or predict based on textual clues.\\nFor example, \\nExcerpt:\\n\"Studies have shown that prolonged exposure to stress can negatively impact cognitive function, particularly memory and decision-making. This is because chronic stress leads to an overproduction of cortisol, a hormone that, in excessive amounts, has been linked to neural atrophy in the hippocampus, a brain region crucial for memory formation.\"\\nLiteral Question:\\n\"According to the passage, what is one effect of chronic stress on the brain?\"\\n(Answer: Neural atrophy in the hippocampus, affecting memory formation.)\\nInferential Question:\\n\"Based on the passage, why might individuals in high-stress professions experience difficulty making decisions?\"\\n(Answer: The passage states that chronic stress impairs cognitive functions like decision-making. Since high-stress professions expose individuals to prolonged stress, they may experience cognitive difficulties due to excessive cortisol affecting brain regions involved in these functions.)\\n\\n**What is cause-and-effect inference?**\\nDefinition: Identifying unstated causes or effects based on textual evidence.\\nExample Question: What is the likely cause of X, given the author’s argument?\\nExample Application:\\nText: Prolonged exposure to air pollution has been linked to cognitive decline in older adults.\\nInference: Long-term air pollution exposure may impair brain function.\\n\\n[GUIDELINES]\\nStep1: Summarize your understanding of what referential questions are and what is cause-and-effect inference. \\nStep 2: Based on your understanding of what referential questions are, generate one mutliple-choice referential question based on the text provided by the user. This questions should be cause-and-effect inference.  \\nPrint out your reasoning before you print out the question-answer pairs. \\n',\n",
       " 'user_prompt_inferential': '<text>\\n{text}\\n</text>\\n'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prompts(\"prompts.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
