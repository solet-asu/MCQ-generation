{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the files in data folder\n",
    "files_to_process =  get_files_in_directory(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_text_file('../data/text3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text = add_chunk_markers(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.planner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique invocation ID for this workflow run\n",
    "invocation_id = str(uuid.uuid4())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = await generate_plan(\n",
    "    invocation_id=invocation_id,\n",
    "    model=\"gpt-4o\",\n",
    "    text=chunked_text, \n",
    "    fact = 1, \n",
    "    inference = 1, \n",
    "    table_name = \"plan_metadata\", \n",
    "    database_file = \"../database/mcq_metadata.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.controller_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact =1\n",
    "inference = 1\n",
    "main_idea = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = create_task_list(chunked_text, plan, fact, inference, main_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task_list[0]\n",
    "task.get(\"question_type\", \"\").lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MCQ Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mcq_generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = await generate_all_mcqs(task_list, invocation_id, \n",
    "                                    model=\"gpt-4o\", \n",
    "                                    mcq_metadata_table_name=\"mcq_metadata\", \n",
    "                                    evaluation_metadata_table_name=\"evaluation_metadata\",\n",
    "                                    database_file=\"../database/mcq_metadata.db\",\n",
    "                                    max_attempt=3,\n",
    "                                    concurrency=30,\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = await generate_all_mcqs_quality_first(task_list, \n",
    "                                                  invocation_id, \n",
    "                                    model=\"gpt-4o\", \n",
    "                                    mcq_metadata_table_name=\"mcq_metadata\", \n",
    "                                    evaluation_metadata_table_name=\"evaluation_metadata\",\n",
    "                                    ranking_metadata_table_name=\"ranking_metadata\",\n",
    "                                    database_file=\"../database/mcq_metadata.db\",\n",
    "                                    max_attempt=3,\n",
    "                                    candidate_num=5,\n",
    "                                    concurrency=30,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quality-first MCQ generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_metadata = await generate_mcq_quality_first(\n",
    "    invocation_id=invocation_id,\n",
    "    model=\"gpt-4o\",\n",
    "    task=task_list[0],\n",
    "    mcq_table_name=\"mcq_metadata\",\n",
    "    ranking_table_name=\"ranking_metadata\",\n",
    "    database_file='../database/mcq_metadata.db',\n",
    "    max_attempt = 3,\n",
    "    attempt= 1,\n",
    "    candidate_num = 5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.formatter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_questions = reformat_mcq_metadata(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Full Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.general import *\n",
    "\n",
    "# get all the files in data folder\n",
    "files_to_process =  get_files_in_directory(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_text_file('../data/text3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.workflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await question_generation_workflow(text, \n",
    "                                            fact = 1, \n",
    "                                            inference = 1, \n",
    "                                            main_idea = 1, \n",
    "                                            model = \"gpt-5\", \n",
    "                                            quality_first = True, \n",
    "                                            candidate_num =5,\n",
    "                                            max_attempt_for_single_mcq = 3,\n",
    "                                            plan_metadata_table_name = \"plan_metadata\",\n",
    "                                            mcq_metadata_table_name = \"mcq_metadata\",\n",
    "                                            evaluation_metadata_table_name = \"evaluation_metadata\",\n",
    "                                            ranking_metadata_table_name = \"ranking_metadata\",\n",
    "                                            workflow_metadata_table_name = \"workflow_metadata\", \n",
    "                                            database_file = \"../database/mcq_metadata.db\",\n",
    "                                            concurrency = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the output from database to a CSV file \n",
    "from src.database_handler import export_table_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_csv(\n",
    "    table_name=\"mcq_metadata\",\n",
    "    file_name=\"20250530_mcq_metadata.csv\",\n",
    "    database_file=\"../database/mcq_metadata.db\",\n",
    "\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
