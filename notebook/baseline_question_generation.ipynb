{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c39da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASU LEI Team - Baseline Question Generation\n",
    "# Research Assistant: Shubham\n",
    "# Task: Generate baseline MCQs from source texts using GPT-5\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from openai import AsyncOpenAI\n",
    "import re\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Enable nested async for Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"ASU LEI Team - Baseline Question Generation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Set up paths\n",
    "project_root = Path.cwd().parent if 'notebook' in str(Path.cwd()) else Path.cwd()\n",
    "database_dir = project_root / \"database\"\n",
    "source_texts_dir = database_dir  # Adjust if your source texts are in a different location\n",
    "\n",
    "# OpenAI Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"WARNING: OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Please set your API key: export OPENAI_API_KEY='your-key'\")\n",
    "    OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ee4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: IMPORT ALL TEXTS INTO CSV WITH UNIQUE IDs\n",
    "# =============================================================================\n",
    "\n",
    "def create_source_texts_csv():\n",
    "    \"\"\"\n",
    "    Import all text files from subject folders and create source_texts.csv\n",
    "    with unique IDs in format: subject_chapter_section\n",
    "    \"\"\"\n",
    "    print(\"\\nSTEP 1: Creating source_texts.csv from downloaded files...\")\n",
    "    \n",
    "    # Define the subjects and their folders\n",
    "    subjects = [\"Anthropology\", \"History\", \"Lifespan Development\", \"Sociology\"]\n",
    "    \n",
    "    source_texts_data = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "        subject_folder = source_texts_dir / subject\n",
    "        \n",
    "        if not subject_folder.exists():\n",
    "            print(f\"Warning: Folder '{subject}' not found in {source_texts_dir}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing {subject} folder...\")\n",
    "        \n",
    "        # Get all .txt files in the subject folder\n",
    "        txt_files = list(subject_folder.glob(\"*.txt\"))\n",
    "        \n",
    "        for txt_file in txt_files:\n",
    "            # Extract chapter.section from filename (e.g., \"1.2.txt\" -> \"1\", \"2\")\n",
    "            filename = txt_file.stem  # removes .txt extension\n",
    "            \n",
    "            try:\n",
    "                # Handle filenames like \"1.2\", \"3.1\", \"11.2\", etc.\n",
    "                if '.' in filename:\n",
    "                    chapter, section = filename.split('.', 1)\n",
    "                else:\n",
    "                    # Handle single number files\n",
    "                    chapter = filename\n",
    "                    section = \"1\"\n",
    "                \n",
    "                # Create textID in format: subject_chapter_section\n",
    "                subject_clean = subject.lower().replace(\" \", \"_\")\n",
    "                text_id = f\"{subject_clean}_{chapter}_{section}\"\n",
    "                \n",
    "                # Read the text file with UTF-8 encoding to preserve diacritical marks\n",
    "                try:\n",
    "                    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "                        text_content = f.read().strip()\n",
    "                    \n",
    "                    if text_content:  # Only add non-empty files\n",
    "                        source_texts_data.append({\n",
    "                            'textID': text_id,\n",
    "                            'text': text_content\n",
    "                        })\n",
    "                        print(f\" Added: {text_id} ({len(text_content)} characters)\")\n",
    "                    else:\n",
    "                        print(f\" Skipped empty file: {txt_file}\")\n",
    "                        \n",
    "                except UnicodeDecodeError:\n",
    "                    print(f\"Error reading {txt_file}: Encoding issue\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {txt_file}: {e}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing filename {filename}: {e}\")\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    if source_texts_data:\n",
    "        df_source_texts = pd.DataFrame(source_texts_data)\n",
    "        output_file = database_dir / \"source_texts.csv\"\n",
    "        df_source_texts.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"\\nCreated source_texts.csv with {len(source_texts_data)} texts\")\n",
    "        print(f\"Saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample\n",
    "        print(f\"\\nSample entries:\")\n",
    "        for i, row in df_source_texts.head(3).iterrows():\n",
    "            print(f\"  {row['textID']}: {row['text'][:100]}...\")\n",
    "            \n",
    "        return df_source_texts\n",
    "    else:\n",
    "        print(\"No text files found! Please check your folder structure.\")\n",
    "        return None\n",
    "\n",
    "# Execute Step 1\n",
    "df_source_texts = create_source_texts_csv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: QUESTION GENERATION WORKFLOW USING GPT-5\n",
    "# =============================================================================\n",
    "\n",
    "# The exact prompt from the task specification\n",
    "QUESTION_GENERATION_PROMPT = \"\"\"<source>\n",
    "{source_text}\n",
    "</source>\n",
    "\n",
    "[Your Task]:\n",
    "\n",
    "Generate **five multiple-choice questions** based on the source text above.\n",
    "\n",
    "- Include **two factual questions**, **two inferential questions**, and **one main idea question**.\n",
    "\n",
    "### Question Type Definitions:\n",
    "\n",
    "- **Factual Question**: Requires recall of specific facts or details explicitly stated in the source text.\n",
    "\n",
    "- **Inferential Question**: Requires the student to go beyond what is directly stated in the text and draw a logical conclusion using textual evidence, reasoning, and sometimes prior knowledge. The answer is *implied*, not explicitly stated.\n",
    "\n",
    "- **Main Idea Question**: Assesses the ability to identify the central point, primary purpose, or overall message of the text. It should *not* focus on minor details, examples, or secondary arguments.\n",
    "\n",
    "### Output Format:\n",
    "\n",
    "Return the response in the following JSON structure:\n",
    "\n",
    "```json\n",
    "{{\n",
    "\"question1\": {{\n",
    "\"type\": \"factual\",\n",
    "\"question\": \"<QUESTION>Your first factual question stem with four options:\\\\nA) ...\\\\nB) ...\\\\nC) ...\\\\nD) ...</QUESTION>\",\n",
    "\"answer\": \"<ANSWER>C) Correct answer text</ANSWER>\"\n",
    "}},\n",
    "\"question2\": {{\n",
    "\"type\": \"factual\",\n",
    "\"question\": \"<QUESTION>Your second factual question stem with four options:\\\\nA) ...\\\\nB) ...\\\\nC) ...\\\\nD) ...</QUESTION>\",\n",
    "\"answer\": \"<ANSWER>B) Correct answer text</ANSWER>\"\n",
    "}},\n",
    "\"question3\": {{\n",
    "\"type\": \"inferential\",\n",
    "\"question\": \"<QUESTION>Your first inferential question stem with four options:\\\\nA) ...\\\\nB) ...\\\\nC) ...\\\\nD) ...</QUESTION>\",\n",
    "\"answer\": \"<ANSWER>A) Correct answer text</ANSWER>\"\n",
    "}},\n",
    "\"question4\": {{\n",
    "\"type\": \"inferential\",\n",
    "\"question\": \"<QUESTION>Your second inferential question stem with four options:\\\\nA) ...\\\\nB) ...\\\\nC) ...\\\\nD) ...</QUESTION>\",\n",
    "\"answer\": \"<ANSWER>D) Correct answer text</ANSWER>\"\n",
    "}},\n",
    "\"question5\": {{\n",
    "\"type\": \"main idea\",\n",
    "\"question\": \"<QUESTION>Your main idea question stem with four options:\\\\nA) ...\\\\nB) ...\\\\nC) ...\\\\nD) ...</QUESTION>\",\n",
    "\"answer\": \"<ANSWER>C) Correct answer text</ANSWER>\"\n",
    "}}\n",
    "}}\n",
    "```\n",
    "\n",
    "**IMPORTANT** The correct answer letters in the JSON template are just examples. Adjust them as needed.\"\"\"\n",
    "\n",
    "async def generate_questions_for_text(text_id: str, text_content: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate 5 questions for a given text using GPT-5 (or GPT-4 if GPT-5 not available)\n",
    "    \n",
    "    Args:\n",
    "        text_id (str): Unique identifier for the text\n",
    "        text_content (str): The source text content\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Generated questions and metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Format the prompt with the source text\n",
    "        formatted_prompt = QUESTION_GENERATION_PROMPT.format(source_text=text_content)\n",
    "        \n",
    "        # Make API call to GPT (using gpt-4 as gpt-5 may not be available yet)\n",
    "        response = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # Use gpt-4o for now, update to gpt-5 when available\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "            ],\n",
    "            temperature=0.7,  # Some creativity for question variety\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        result_text = response.choices[0].message.content\n",
    "        \n",
    "        # Try to extract JSON from the response\n",
    "        try:\n",
    "            # Look for JSON block in the response\n",
    "            json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', result_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "            else:\n",
    "                # Try to find JSON without code block markers\n",
    "                json_match = re.search(r'(\\{.*?\\})', result_text, re.DOTALL)\n",
    "                if json_match:\n",
    "                    json_str = json_match.group(1)\n",
    "                else:\n",
    "                    raise ValueError(\"No JSON found in response\")\n",
    "            \n",
    "            questions_data = json.loads(json_str)\n",
    "            \n",
    "            return {\n",
    "                'text_id': text_id,\n",
    "                'success': True,\n",
    "                'questions': questions_data,\n",
    "                'raw_response': result_text\n",
    "            }\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error for {text_id}: {e}\")\n",
    "            return {\n",
    "                'text_id': text_id,\n",
    "                'success': False,\n",
    "                'error': f\"JSON decode error: {e}\",\n",
    "                'raw_response': result_text\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"API error for {text_id}: {e}\")\n",
    "        return {\n",
    "            'text_id': text_id,\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'raw_response': None\n",
    "        }\n",
    "\n",
    "async def process_all_texts(df_source_texts: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process all texts and generate questions for each\n",
    "    \n",
    "    Args:\n",
    "        df_source_texts (pd.DataFrame): DataFrame with textID and text columns\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: Results for all texts\n",
    "    \"\"\"\n",
    "    print(f\"\\nSTEP 2: Generating questions for {len(df_source_texts)} texts...\")\n",
    "    print(\"Using baseline prompt (no advanced strategies)\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for index, row in df_source_texts.iterrows():\n",
    "        text_id = row['textID']\n",
    "        text_content = row['text']\n",
    "        \n",
    "        print(f\"\\nProcessing {index + 1}/{len(df_source_texts)}: {text_id}\")\n",
    "        print(f\"Text length: {len(text_content)} characters\")\n",
    "        \n",
    "        # Generate questions\n",
    "        result = await generate_questions_for_text(text_id, text_content)\n",
    "        results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"Successfully generated 5 questions for {text_id}\")\n",
    "        else:\n",
    "            print(f\"Failed to generate questions for {text_id}: {result['error']}\")\n",
    "        \n",
    "        # Small delay to avoid rate limiting\n",
    "        await asyncio.sleep(1)\n",
    "    \n",
    "    # Summary\n",
    "    successful = len([r for r in results if r['success']])\n",
    "    print(f\"\\nGENERATION SUMMARY:\")\n",
    "    print(f\"Total texts processed: {len(results)}\")\n",
    "    print(f\"Successful: {successful}\")\n",
    "    print(f\"Failed: {len(results) - successful}\")\n",
    "    print(f\"Success rate: {successful/len(results)*100:.1f}%\")\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: EXPORT RESULTS TO BASELINE_QUESTIONS.CSV\n",
    "# =============================================================================\n",
    "\n",
    "def create_baseline_questions_csv(results: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create the baseline_questions.csv file from generation results\n",
    "    \n",
    "    Args:\n",
    "        results (List[Dict]): Results from question generation\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The baseline questions dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\nSTEP 3: Creating baseline_questions.csv...\")\n",
    "    \n",
    "    baseline_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        if not result['success']:\n",
    "            print(f\"Skipping failed generation for {result['text_id']}\")\n",
    "            continue\n",
    "            \n",
    "        text_id = result['text_id']\n",
    "        questions = result['questions']\n",
    "        \n",
    "        # Get the source text\n",
    "        source_text = df_source_texts[df_source_texts['textID'] == text_id]['text'].iloc[0]\n",
    "        \n",
    "        # Process each question (question1 through question5)\n",
    "        for q_num in range(1, 6):\n",
    "            q_key = f\"question{q_num}\"\n",
    "            \n",
    "            if q_key in questions:\n",
    "                q_data = questions[q_key]\n",
    "                \n",
    "                baseline_data.append({\n",
    "                    'textID': text_id,\n",
    "                    'text': source_text,\n",
    "                    'baseline_question_type': q_data['type'],\n",
    "                    'baseline_question': q_data['question'],\n",
    "                    'baseline_answer': q_data['answer']\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_baseline = pd.DataFrame(baseline_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = database_dir / \"baseline_questions.csv\"\n",
    "    df_baseline.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Created baseline_questions.csv with {len(baseline_data)} questions\")\n",
    "    print(f\"Saved to: {output_file}\")\n",
    "    \n",
    "    # Display summary by question type\n",
    "    if not df_baseline.empty:\n",
    "        type_counts = df_baseline['baseline_question_type'].value_counts()\n",
    "        print(f\"\\nQuestion types generated:\")\n",
    "        for q_type, count in type_counts.items():\n",
    "            print(f\"  {q_type}: {count}\")\n",
    "        \n",
    "        # Show sample questions\n",
    "        print(f\"\\nSample questions:\")\n",
    "        for q_type in ['factual', 'inferential', 'main idea']:\n",
    "            sample = df_baseline[df_baseline['baseline_question_type'] == q_type].head(1)\n",
    "            if not sample.empty:\n",
    "                row = sample.iloc[0]\n",
    "                print(f\"\\n{q_type.title()} Question Example:\")\n",
    "                print(f\"Text: {row['textID']}\")\n",
    "                print(f\"Q: {row['baseline_question'][:100]}...\")\n",
    "                print(f\"A: {row['baseline_answer']}\")\n",
    "    \n",
    "    return df_baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d85706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    if df_source_texts is None or df_source_texts.empty:\n",
    "        print(\"Cannot proceed: No source texts loaded\")\n",
    "        return\n",
    "    \n",
    "    # Generate questions for all texts\n",
    "    results = await process_all_texts(df_source_texts)\n",
    "    \n",
    "    # Create baseline questions CSV\n",
    "    df_baseline = create_baseline_questions_csv(results)\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\nTASK COMPLETION SUMMARY:\")\n",
    "    print(f\"Step 1: source_texts.csv created with {len(df_source_texts)} texts\")\n",
    "    print(f\"Step 2: Questions generated using baseline prompt\")\n",
    "    print(f\"Step 3: baseline_questions.csv created with {len(df_baseline)} questions\")\n",
    "    print(f\"\\nFiles created in {database_dir}:\")\n",
    "    print(f\"  - source_texts.csv\")\n",
    "    print(f\"  - baseline_questions.csv\")\n",
    "    print(f\"\\nCompleted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Run the main function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcqwork",
   "language": "python",
   "name": "mcqwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
