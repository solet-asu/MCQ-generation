{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42e52e2",
   "metadata": {},
   "source": [
    "### Test the question type classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e4e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.general import read_csv_file, extract_json_string\n",
    "from src.prompt_fetch import get_prompts\n",
    "from src.agent import Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40229d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv files from the data directory \n",
    "question_dir = \"../data/all_mcqs.csv\"\n",
    "text_dir = \"../data/all_texts.csv\"\n",
    "\n",
    "mcqs = read_csv_file(question_dir)\n",
    "texts = read_csv_file(text_dir)\n",
    "\n",
    "# convert texts into a pandas datafram\n",
    "texts_df = pd.DataFrame(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146647a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = mcqs[1].get(\"Question\", \"None\")\n",
    "question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda9a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prompt for question type classification\n",
    "prompt = get_prompts(\"question_type_classifier.yaml\")\n",
    "\n",
    "system_prompt = prompt.get(\"system_prompt\", \"\")\n",
    "user_prompt = prompt.get(\"user_prompt\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "chapters = []    \n",
    "sections = []\n",
    "sources  = []\n",
    "questions = []\n",
    "original_labels=[]   \n",
    "classification_labels = []\n",
    "reasonings = []\n",
    "\n",
    "\n",
    "# test on the first 100 questions \n",
    "for i in range(100):\n",
    "    print(f\"-------------------------------Processing question {i+1}...---------------------------------\")\n",
    "    question = mcqs[i].get(\"Question\", \"None\")\n",
    "    \n",
    "    # find the corresponding text for the question \n",
    "    subject = mcqs[i].get(\"Subject\", \"None\")\n",
    "    chapter = mcqs[i].get(\"Chapter\", \"None\")\n",
    "    section = mcqs[i].get(\"Section\", \"None\")\n",
    "    original_label = mcqs[i].get(\"Question_type\", \"None\")\n",
    "    \n",
    "    # choose the text according to the subject, chapter, and section\n",
    "    text_df = texts_df[(texts_df[\"Subject\"] == subject) &      \n",
    "                        (texts_df[\"Chapter\"] == chapter) & \n",
    "                        (texts_df[\"Section\"] == section)]\n",
    "    text = text_df[\"Text\"].values[0] if not text_df.empty else \"None\"\n",
    "\n",
    "    if text == \"None\":\n",
    "        print(f\"No text found for question {i+1}: {question}\")\n",
    "        continue\n",
    "    \n",
    "    subjects.append(subject)\n",
    "    chapters.append(chapter)\n",
    "    sections.append(section)\n",
    "    sources.append(text)\n",
    "    questions.append(question)\n",
    "    original_labels.append(original_label)\n",
    "    \n",
    "    formatted_user_prompt = user_prompt.format(question=question, source=text)\n",
    "    # create an agent\n",
    "    classification_agent = Agent(\n",
    "                    model='gpt-4o',\n",
    "                    system_prompt=system_prompt,\n",
    "                    user_prompt=formatted_user_prompt\n",
    "                )\n",
    "    # run the agent to evaluate the question\n",
    "    response = await classification_agent.completion_generation()\n",
    "\n",
    "    result = extract_json_string(response)\n",
    "    classification = result.get(\"classification\", \"None\")\n",
    "    reasoning = result.get(\"reasoning\", \"None\")\n",
    "    reasonings.append(reasoning)\n",
    "    print(f\">>>>>>>>Classification for question {i+1}: {classification}\")\n",
    "    if classification == \"None\":\n",
    "        print(f\"No classification found for question {i+1}: {question}\")\n",
    "    elif classification == \"factual question\":\n",
    "        classification_labels.append(\"fact\")\n",
    "    elif classification == \"inferential question\":\n",
    "        classification_labels.append(\"inference\")\n",
    "    elif classification == \"main idea question\":\n",
    "        classification_labels.append(\"main_idea\")\n",
    "    else:\n",
    "        classification_labels.append(\"Unknown\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05d3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to store the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Subject\": subjects,\n",
    "    \"Chapter\": chapters,\n",
    "    \"Section\": sections,\n",
    "    \"Source\": sources,\n",
    "    \"Question\": questions,\n",
    "    \"Original_Label\": original_labels,\n",
    "    \"Classification_Label\": classification_labels,\n",
    "    \"Reasoning\": reasonings\n",
    "})\n",
    "\n",
    "# save the results to a csv file\n",
    "results_df.to_csv(\"../output/question_type_classification_results_updated.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
